{"paragraphs":[{"text":"%flink\n\nimport org.apache.flink.api.scala._\nimport org.apache.flink.streaming.api.scala.StreamExecutionEnvironment\nimport org.apache.flink.streaming.api.windowing.time.Time\nimport org.apache.flink.streaming.api.windowing.assigners._;\nimport org.apache.flink.streaming.api.scala.DataStream\nimport org.apache.flink.api.common.typeinfo.TypeInformation;\nimport org.apache.flink.api.java.typeutils.TypeExtractor;\nimport org.apache.flink.streaming.util.serialization.{DeserializationSchema, SerializationSchema}\nimport org.apache.flink.streaming.util.serialization.SimpleStringSchema\nimport org.apache.flink.streaming.api.datastream.DataStreamSource\nimport scala.collection.JavaConverters._\nimport scala.util.Try\n\ncase class AntPosition(id: String, x: Int, y: Int, timestamp: Long, moved: Boolean = false ){\n   override def toString( ): String = List(id,x,y,timestamp,moved) mkString \",\"\n}\n    \nobject AntPosition {\n  def fromString(line: String): AntPosition = {\n    val tokens: Array[String] = line.split(\",\")\n    if (tokens.length != 5) {\n      throw new RuntimeException(\"Invalid record: \" + line)\n    }\n    println(tokens(0))\n    new AntPosition(tokens(0),tokens(1).toInt,tokens(2).toInt,tokens(3).toLong,tokens(4).toBoolean) \n  }\n  def isMoved(moved: String): Boolean = {\n    moved.toBoolean\n  }\n}\n\nclass AntPositionSchema extends DeserializationSchema[AntPosition] with SerializationSchema[AntPosition]{\n    /**\n     * Implements a SerializationSchema and DeserializationSchema for AnpPosition for Kafka data sources and sinks.\n     */\n    override def serialize(antPosition: AntPosition): Array[Byte] = antPosition.toString.getBytes\n    override def deserialize(message: Array[Byte]): AntPosition = AntPosition.fromString(new String(message))\n    override def isEndOfStream(nextElement: AntPosition): Boolean = false\n    override def getProducedType(): TypeInformation[AntPosition] =  TypeExtractor.getForClass(classOf[AntPosition])\n}","dateUpdated":"2017-05-29T03:30:59+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","tableHide":false,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1496028205890_-1456720816","id":"20170528-173949_891253161","result":{"code":"SUCCESS","type":"TEXT","msg":"import org.apache.flink.api.scala._\nimport org.apache.flink.streaming.api.scala.StreamExecutionEnvironment\nimport org.apache.flink.streaming.api.windowing.time.Time\nimport org.apache.flink.streaming.api.windowing.assigners._\nimport org.apache.flink.streaming.api.scala.DataStream\nimport org.apache.flink.api.common.typeinfo.TypeInformation\nimport org.apache.flink.api.java.typeutils.TypeExtractor\nimport org.apache.flink.streaming.util.serialization.{DeserializationSchema, SerializationSchema}\nimport org.apache.flink.streaming.util.serialization.SimpleStringSchema\nimport org.apache.flink.streaming.api.datastream.DataStreamSource\nimport scala.collection.JavaConverters._\nimport scala.util.Try\ndefined class AntPosition\ndefined module AntPosition\ndefined class AntPositionSchema\n"},"dateCreated":"2017-05-29T03:23:25+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:4036","dateFinished":"2017-05-29T03:31:10+0000","dateStarted":"2017-05-29T03:30:59+0000"},{"text":"%angular   \r\n\r\n<style>\r\n    .block{\r\n        display: block;\r\n    }\r\n</style>\r\n\r\n<script>\r\nzeppelin.addComponent(\r\n    \"antCollisionHeatmap\",\r\n    \"<?xml version='1.0' standalone='no?'>\"+ \r\n\"<!DOCTYPE svg PUBLIC '-//W3C//DTD SVG 1.1//EN' \"+ \r\n  \"'http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd'>\"+ \r\n  \"<svg width='1268px' height='808px' viewBox='0 0 1150 720' stroke='white' version='1.1'\"+\r\n\"     xmlns='http://www.w3.org/2000/svg' xmlns:xlink='http://www.w3.org/1999/xlink'>\"+\r\n\"</svg>\", \r\n    function(scope, element) {\r\n       \r\n        element.addClass('block');\r\n        \r\n        var rects = []\r\n    \r\n\t\r\n\t\tvar cellSize = 7;\r\n        var gridSize = 100;\r\n        var svg = d3.select($(element).children(\"svg\")[0])\r\n        if (svg != undefined ){\r\n            svg.append(\"rect\")\r\n                .attr(\"x\", 0)\r\n                .attr(\"y\", 0)\r\n                .attr(\"width\", cellSize*gridSize)\r\n                .attr(\"height\", cellSize*gridSize)\r\n                .attr('fill-opacity', 0.1)\r\n                .style(\"fill\", \"#F7F7F7\");\r\n        }\r\n        function mapRect(rect) {\r\n            return {\r\n                y: ((rect.y-1)*cellSize),\r\n                x: ((rect.x-1)*cellSize),\r\n            }\r\n        }\r\n        \r\n        var requested = false;\r\n        \r\n        function addRect(rect) {\r\n            var cordinates = mapRect(rect);\r\n            var id = rect.id;\r\n            if(rects[id] == undefined)\r\n                rects[id] = rect\r\n             rects[id].cordinates = cordinates;\r\n        }\r\n        \r\n        var stop = false;\r\n        function draw() {\r\n          \r\n          for(var i = 0; i<rects.length;i++){\r\n            if(rects[i] != undefined){\r\n                var rect = rects[i];\r\n                rect.svg = svg.append(\"rect\")\r\n                    .attr(\"width\", cellSize)\r\n                    .attr(\"height\", cellSize)\r\n                    .attr(\"x\", rect.cordinates.x)\r\n                    .attr(\"y\", rect.cordinates.y)\r\n                    .attr(\"id\", i)\r\n                    .attr(\"stroke-width\", 0)\r\n                    .attr('fill-opacity', 0.1)\r\n                    .style(\"fill\", \"#F23030\");\r\n             }\r\n          }\r\n        }\r\n        \r\n    \r\n        \r\n        var init = false;\r\n        var remove = scope.$watch('ants', function(newAnts, oldValue) {\r\n            console.log(newAnts);\r\n            console.log(oldValue);\r\n            if(newAnts!=undefined)\r\n                newAnts.forEach(function(newAnt){\r\n                    addRect({id:newAnt._1,x:newAnt._2,y:newAnt._3})\r\n                })\r\n             window.requestAnimationFrame(draw); \r\n        });\r\n        \r\n        // We have to clean-up, if the ui-element is reloaded\r\n        scope.$on('clean', function() {\r\n            remove()\r\n            stop = true;\r\n        });\r\n       \r\n    })\r\n</script>","dateUpdated":"2017-05-29T03:30:59+0000","config":{"colWidth":6,"editorMode":"ace/mode/html","graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1496028205891_-1457105565","id":"20170528-190626_1705822270","result":{"code":"SUCCESS","type":"ANGULAR","msg":"<style>\r\n    .block{\r\n        display: block;\r\n    }\r\n</style>\r\n\r\n<script>\r\nzeppelin.addComponent(\r\n    \"antCollisionHeatmap\",\r\n    \"<?xml version='1.0' standalone='no?'>\"+ \r\n\"<!DOCTYPE svg PUBLIC '-//W3C//DTD SVG 1.1//EN' \"+ \r\n  \"'http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd'>\"+ \r\n  \"<svg width='1268px' height='808px' viewBox='0 0 1150 720' stroke='white' version='1.1'\"+\r\n\"     xmlns='http://www.w3.org/2000/svg' xmlns:xlink='http://www.w3.org/1999/xlink'>\"+\r\n\"</svg>\", \r\n    function(scope, element) {\r\n       \r\n        element.addClass('block');\r\n        \r\n        var rects = []\r\n    \r\n\t\r\n\t\tvar cellSize = 7;\r\n        var gridSize = 100;\r\n        var svg = d3.select($(element).children(\"svg\")[0])\r\n        if (svg != undefined ){\r\n            svg.append(\"rect\")\r\n                .attr(\"x\", 0)\r\n                .attr(\"y\", 0)\r\n                .attr(\"width\", cellSize*gridSize)\r\n                .attr(\"height\", cellSize*gridSize)\r\n                .attr('fill-opacity', 0.1)\r\n                .style(\"fill\", \"#F7F7F7\");\r\n        }\r\n        function mapRect(rect) {\r\n            return {\r\n                y: ((rect.y-1)*cellSize),\r\n                x: ((rect.x-1)*cellSize),\r\n            }\r\n        }\r\n        \r\n        var requested = false;\r\n        \r\n        function addRect(rect) {\r\n            var cordinates = mapRect(rect);\r\n            var id = rect.id;\r\n            if(rects[id] == undefined)\r\n                rects[id] = rect\r\n             rects[id].cordinates = cordinates;\r\n        }\r\n        \r\n        var stop = false;\r\n        function draw() {\r\n          \r\n          for(var i = 0; i<rects.length;i++){\r\n            if(rects[i] != undefined){\r\n                var rect = rects[i];\r\n                rect.svg = svg.append(\"rect\")\r\n                    .attr(\"width\", cellSize)\r\n                    .attr(\"height\", cellSize)\r\n                    .attr(\"x\", rect.cordinates.x)\r\n                    .attr(\"y\", rect.cordinates.y)\r\n                    .attr(\"id\", i)\r\n                    .attr(\"stroke-width\", 0)\r\n                    .attr('fill-opacity', 0.1)\r\n                    .style(\"fill\", \"#F23030\");\r\n             }\r\n          }\r\n        }\r\n        \r\n    \r\n        \r\n        var init = false;\r\n        var remove = scope.$watch('ants', function(newAnts, oldValue) {\r\n            console.log(newAnts);\r\n            console.log(oldValue);\r\n            if(newAnts!=undefined)\r\n                newAnts.forEach(function(newAnt){\r\n                    addRect({id:newAnt._1,x:newAnt._2,y:newAnt._3})\r\n                })\r\n             window.requestAnimationFrame(draw); \r\n        });\r\n        \r\n        // We have to clean-up, if the ui-element is reloaded\r\n        scope.$on('clean', function() {\r\n            remove()\r\n            stop = true;\r\n        });\r\n       \r\n    })\r\n</script>"},"dateCreated":"2017-05-29T03:23:25+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:4037","dateFinished":"2017-05-29T03:30:59+0000","dateStarted":"2017-05-29T03:30:59+0000"},{"text":"%flink \nimport scala.collection.JavaConverters._\nimport org.apache.zeppelin.flink.FlinkInterpreter;\nimport org.apache.zeppelin.flink.ui._;\n\n\nclass AntCollisionHeatmapUI() extends UIComponent[List[(String,Int,Int)],Any](classOf[Any]) {\n\n   scope.remove(\"ants\")\n   \n   override def invoke(item:List[(String,Int,Int)]): Unit = {\n       scope.put(\"ants\" , item.asJava);\n   }\n   \n   def getTemplate(): String = {\n       \"<ant-collision-heatmap></ant-collision-heatmap>>\"\n   }\n}\n","dateUpdated":"2017-05-29T03:30:59+0000","config":{"colWidth":6,"editorMode":"ace/mode/scala","graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1496028205891_-1457105565","id":"20170528-191450_1520446058","result":{"code":"SUCCESS","type":"TEXT","msg":"import scala.collection.JavaConverters._\nimport org.apache.zeppelin.flink.FlinkInterpreter\nimport org.apache.zeppelin.flink.ui._\ndefined class AntCollisionHeatmapUI\n"},"dateCreated":"2017-05-29T03:23:25+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:4038","dateFinished":"2017-05-29T03:31:16+0000","dateStarted":"2017-05-29T03:30:59+0000"},{"text":"%flink \nvar antCollisionHeatMap = new AntCollisionHeatmapUI()","dateUpdated":"2017-05-29T03:30:59+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","tableHide":false,"graph":{"mode":"table","height":289,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1496028205892_-1459029309","id":"20170528-225028_1410302774","result":{"code":"SUCCESS","type":"ANGULAR","msg":"\n<ant-collision-heatmap></ant-collision-heatmap>>\n"},"dateCreated":"2017-05-29T03:23:25+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:4039","dateFinished":"2017-05-29T03:31:17+0000","dateStarted":"2017-05-29T03:31:11+0000"},{"text":"%flink \n\nimport java.util.Properties\nimport org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumer09\n\n  //  val env = StreamExecutionEnvironment.createLocalEnvironment()\n\n    val kafkaConsumerProperties = new Properties()\n    kafkaConsumerProperties.put(\"zookeeper.connect\",\"192.168.99.100:2181\")\n    kafkaConsumerProperties.put(\"group.id\", \"flinkZeppelin\")\n    kafkaConsumerProperties.put(\"bootstrap.servers\",\"192.168.99.100:32770\")\n    kafkaConsumerProperties.put(\"auto.offset.reset\",\"earliest\")\n    println(kafkaConsumerProperties)\n\n    var kafkaConsumer: FlinkKafkaConsumer09[AntPosition] = new FlinkKafkaConsumer09[AntPosition](\n      \"ants\",\n      new AntPositionSchema(),\n      kafkaConsumerProperties) \n//  create a TaxiRide data stream\n    val antMoves: DataStream[AntPosition] = senv.addSource(kafkaConsumer)    \n    \n    var time = TumblingProcessingTimeWindows.of(Time.milliseconds(100));\n    \n    val ants = antMoves\n        .keyBy(\"id\")\n        .window(time)\n        .maxBy(\"timestamp\")\n        .filter(k => !k.moved)\n        .map(x=>(x.id,x.x,x.y))\n        .windowAll(time)\n        .fold(List.empty[(String, Int, Int)]) { (acc, v) =>  v :: acc}\n        .addSink(antCollisionHeatMap.getSink())\n\n      \n    //ants.print()\n   // env.execute()\n","dateUpdated":"2017-05-29T03:30:59+0000","config":{"tableHide":false,"colWidth":12,"editorMode":"ace/mode/scala","editorHide":false,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1496028205892_-1459029309","id":"20170528-224131_2011828558","result":{"code":"SUCCESS","type":"TEXT","msg":"import java.util.Properties\nimport org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumer09\nkafkaConsumerProperties: java.util.Properties = {}\nres102: Object = null\nres103: Object = null\nres104: Object = null\nres105: Object = null\n{auto.offset.reset=earliest, bootstrap.servers=192.168.99.100:32770, group.id=flinkZeppelin, zookeeper.connect=192.168.99.100:2181}\nkafkaConsumer: org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumer09[AntPosition] = org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumer09@6fda058e\nantMoves: org.apache.flink.streaming.api.scala.DataStream[AntPosition] = org.apache.flink.streaming.api.scala.DataStream@b1c7458\ntime: org.apache.flink.streaming.api.windowing.assigners.TumblingProcessingTimeWindows = TumblingProcessingTimeWindows(100)\nants: org.apache.flink.streaming.api.datastream.DataStreamSink[List[(String, Int, Int)]] = org.apache.flink.streaming.api.datastream.DataStreamSink@10695b73\n"},"dateCreated":"2017-05-29T03:23:25+0000","dateStarted":"2017-05-29T03:31:17+0000","dateFinished":"2017-05-29T03:31:27+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:4040"},{"text":"%flink \nsenv.execute( )","dateUpdated":"2017-05-29T03:30:59+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","editorHide":false,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1496028205892_-1459029309","id":"20170528-224922_1194789313","result":{"code":"ERROR","type":"TEXT","msg":"Submitting job with JobID: 5b68b6204e0631ede89bdd003590cf0c. Waiting for job completion.\n05/29/2017 03:17:21\tJob execution switched to status RUNNING.\n05/29/2017 03:17:21\tSource: Custom Source(1/1) switched to SCHEDULED \n05/29/2017 03:17:21\tSource: Custom Source(1/1) switched to DEPLOYING \n05/29/2017 03:17:21\tFast TumblingProcessingTimeWindows(100) of WindowedStream.aggregate(WindowedStream.scala:428) -> Filter -> Map(1/1) switched to SCHEDULED \n05/29/2017 03:17:21\tFast TumblingProcessingTimeWindows(100) of WindowedStream.aggregate(WindowedStream.scala:428) -> Filter -> Map(1/1) switched to DEPLOYING \n05/29/2017 03:17:21\tTriggerWindow(TumblingProcessingTimeWindows(100), FoldingStateDescriptor{serializer=null, initialValue=List(), foldFunction=org.apache.flink.streaming.api.scala.function.util.ScalaFoldFunction@57660982}, ProcessingTimeTrigger(), WindowedStream.fold(AllWindowedStream.java:223))(1/1) switched to SCHEDULED \n05/29/2017 03:17:21\tTriggerWindow(TumblingProcessingTimeWindows(100), FoldingStateDescriptor{serializer=null, initialValue=List(), foldFunction=org.apache.flink.streaming.api.scala.function.util.ScalaFoldFunction@57660982}, ProcessingTimeTrigger(), WindowedStream.fold(AllWindowedStream.java:223))(1/1) switched to DEPLOYING \n05/29/2017 03:17:21\tSink: Unnamed(1/1) switched to SCHEDULED \n05/29/2017 03:17:21\tSink: Unnamed(1/1) switched to DEPLOYING \n05/29/2017 03:17:22\tSink: Unnamed(1/1) switched to RUNNING \n05/29/2017 03:17:22\tFast TumblingProcessingTimeWindows(100) of WindowedStream.aggregate(WindowedStream.scala:428) -> Filter -> Map(1/1) switched to RUNNING \n05/29/2017 03:17:22\tTriggerWindow(TumblingProcessingTimeWindows(100), FoldingStateDescriptor{serializer=null, initialValue=List(), foldFunction=org.apache.flink.streaming.api.scala.function.util.ScalaFoldFunction@57660982}, ProcessingTimeTrigger(), WindowedStream.fold(AllWindowedStream.java:223))(1/1) switched to RUNNING \n05/29/2017 03:17:22\tSource: Custom Source(1/1) switched to RUNNING \n05/29/2017 03:17:51\tJob execution switched to status CANCELLING.\n05/29/2017 03:17:51\tSource: Custom Source(1/1) switched to CANCELING \n05/29/2017 03:17:51\tFast TumblingProcessingTimeWindows(100) of WindowedStream.aggregate(WindowedStream.scala:428) -> Filter -> Map(1/1) switched to CANCELING \n05/29/2017 03:17:51\tTriggerWindow(TumblingProcessingTimeWindows(100), FoldingStateDescriptor{serializer=null, initialValue=List(), foldFunction=org.apache.flink.streaming.api.scala.function.util.ScalaFoldFunction@57660982}, ProcessingTimeTrigger(), WindowedStream.fold(AllWindowedStream.java:223))(1/1) switched to CANCELING \n05/29/2017 03:17:51\tSink: Unnamed(1/1) switched to CANCELING \n05/29/2017 03:17:51\tSource: Custom Source(1/1) switched to CANCELED \n05/29/2017 03:17:51\tTriggerWindow(TumblingProcessingTimeWindows(100), FoldingStateDescriptor{serializer=null, initialValue=List(), foldFunction=org.apache.flink.streaming.api.scala.function.util.ScalaFoldFunction@57660982}, ProcessingTimeTrigger(), WindowedStream.fold(AllWindowedStream.java:223))(1/1) switched to CANCELED \n05/29/2017 03:17:51\tFast TumblingProcessingTimeWindows(100) of WindowedStream.aggregate(WindowedStream.scala:428) -> Filter -> Map(1/1) switched to CANCELED \n05/29/2017 03:17:51\tSink: Unnamed(1/1) switched to CANCELED \n05/29/2017 03:17:51\tJob execution switched to status CANCELED.\norg.apache.flink.client.program.ProgramInvocationException: The program execution failed: Job was cancelled.\n\tat org.apache.flink.client.program.ClusterClient.run(ClusterClient.java:413)\n\tat org.apache.flink.client.program.StandaloneClusterClient.submitJob(StandaloneClusterClient.java:92)\n\tat org.apache.flink.client.program.ClusterClient.run(ClusterClient.java:389)\n\tat org.apache.flink.client.program.ClusterClient.run(ClusterClient.java:381)\n\tat org.apache.flink.streaming.api.environment.RemoteStreamEnvironment.executeRemotely(RemoteStreamEnvironment.java:209)\n\tat org.apache.flink.api.java.ScalaShellRemoteStreamEnvironment.executeRemotely(ScalaShellRemoteStreamEnvironment.java:87)\n\tat org.apache.flink.streaming.api.environment.RemoteStreamEnvironment.execute(RemoteStreamEnvironment.java:173)\n\tat org.apache.flink.streaming.api.environment.StreamExecutionEnvironment.execute(StreamExecutionEnvironment.java:1429)\n\tat org.apache.flink.streaming.api.scala.StreamExecutionEnvironment.execute(StreamExecutionEnvironment.scala:576)\n\tat $$$$dea4bf9c3468418c2713d7c1ed73ea$$$.<init>(<console>:257)\n\tat $$$$dea4bf9c3468418c2713d7c1ed73ea$$$.<clinit>(<console>)\n\tat .<init>(<console>:7)\n\tat .<clinit>(<console>)\n\tat $print(<console>)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat scala.tools.nsc.interpreter.IMain$ReadEvalPrint.call(IMain.scala:734)\n\tat scala.tools.nsc.interpreter.IMain$Request.loadAndRun(IMain.scala:983)\n\tat scala.tools.nsc.interpreter.IMain.loadAndRunReq$1(IMain.scala:573)\n\tat scala.tools.nsc.interpreter.IMain.interpret(IMain.scala:604)\n\tat scala.tools.nsc.interpreter.IMain.interpret(IMain.scala:568)\n\tat org.apache.zeppelin.flink.FlinkInterpreter$1.apply(FlinkInterpreter.java:305)\n\tat org.apache.zeppelin.flink.FlinkInterpreter$1.apply(FlinkInterpreter.java:301)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)\n\tat scala.Console$.withOut(Console.scala:107)\n\tat scala.Console.withOut(Console.scala)\n\tat org.apache.zeppelin.flink.FlinkInterpreter.interpret(FlinkInterpreter.java:299)\n\tat org.apache.zeppelin.flink.FlinkInterpreter.interpret(FlinkInterpreter.java:244)\n\tat org.apache.zeppelin.interpreter.LazyOpenInterpreter.interpret(LazyOpenInterpreter.java:94)\n\tat org.apache.zeppelin.interpreter.remote.RemoteInterpreterServer$InterpretJob.jobRun(RemoteInterpreterServer.java:341)\n\tat org.apache.zeppelin.scheduler.Job.run(Job.java:176)\n\tat org.apache.zeppelin.scheduler.FIFOScheduler$1.run(FIFOScheduler.java:139)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\tat java.lang.Thread.run(Thread.java:745)\nCaused by: org.apache.flink.runtime.client.JobCancellationException: Job was cancelled.\n\tat org.apache.flink.runtime.jobmanager.JobManager$$anonfun$handleMessage$1$$anonfun$applyOrElse$8.apply$mcV$sp(JobManager.scala:814)\n\tat org.apache.flink.runtime.jobmanager.JobManager$$anonfun$handleMessage$1$$anonfun$applyOrElse$8.apply(JobManager.scala:768)\n\tat org.apache.flink.runtime.jobmanager.JobManager$$anonfun$handleMessage$1$$anonfun$applyOrElse$8.apply(JobManager.scala:768)\n\tat scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24)\n\tat scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24)\n\tat akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:41)\n\tat akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:401)\n\tat scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)\n\tat scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.pollAndExecAll(ForkJoinPool.java:1253)\n\tat scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1346)\n\tat scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)\n\tat scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)\n\n"},"dateCreated":"2017-05-29T03:23:25+0000","status":"RUNNING","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:4041","dateStarted":"2017-05-29T03:31:17+0000"},{"text":"%flink ","dateUpdated":"2017-05-29T03:31:00+0000","config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1496028205896_-1460568305","id":"20170529-030319_704750846","result":{"code":"SUCCESS","type":"TEXT","msg":""},"dateCreated":"2017-05-29T03:23:25+0000","status":"PENDING","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:4042"},{"text":"%flink ","dateUpdated":"2017-05-29T03:31:00+0000","config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1496028205896_-1460568305","id":"20170529-031635_1077530097","dateCreated":"2017-05-29T03:23:25+0000","status":"PENDING","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:4043"},{"text":"%flink ","dateUpdated":"2017-05-29T03:31:00+0000","config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1496028660124_-1484961848","id":"20170529-033100_1665418609","dateCreated":"2017-05-29T03:31:00+0000","status":"READY","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:4604"}],"name":"/AntSimulation/CollisionsHeatMap","id":"2CH4PNB5V","lastReplName":{"value":"flink"},"angularObjects":{"2CK59WMT4:shared_process":[],"2CJHHM8RP:shared_process":[],"2CHZP3ZM7:shared_process":[],"2CGCVY5N4:shared_process":[],"2CKM88U6K:shared_process":[],"2CJ9QVFQV:shared_process":[],"2CHWJNY1R:shared_process":[],"2CJ15JRNM:shared_process":[],"2CHR6TTAY:shared_process":[],"2CK5RTUNE:shared_process":[],"2CKPKF8XM:shared_process":[],"2CKC9H57K:shared_process":[],"2CJD253ZF:shared_process":[],"2CM851JQ4:shared_process":[],"2CK35FT1M:shared_process":[],"2CKEFFHGG:shared_process":[],"2CJACCB3H:shared_process":[]},"config":{"looknfeel":"default"},"info":{}}